{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# SEAPORTS ARRIVALS DATA CLEANING\r\n",
    "Additional information about measurement scale: 'Gross capacity' - tones, 'Length' - meters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np \r\n",
    "import pandas as pd "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "column_names = ['Destination seaport code', 'Arrival date', 'Arrival time', 'Departure seaport code', \"Ship's name\", 'Cockade', 'IMO number', 'Call sign', 'Gross capacity', 'Length', 'Agent', 'Berth']\r\n",
    "darlowo = pd.read_csv('data\\Dane_archiwalne_PRZYBYCIA_statków_Darłowo_2005_-_09.2020_DqzvqlF.csv', sep=';', names=column_names, encoding='latin2', skiprows=1)\r\n",
    "gdansk = pd.read_csv('data\\Dane_archiwalne_PRZYBYCIA_statków_do_portu_Gdańsk_2005-06.2020_aERLIVJ.csv', sep=';', names=column_names, encoding='latin2')\r\n",
    "gdansk_nowy_port = pd.read_csv('data\\Dane_archiwalne_PRZYBYCIA_statków_do_portu_Gdańsk_Nowy_Port_2005-06.2020.csv', sep=';', names=column_names, encoding='latin2', skiprows=1)\r\n",
    "gdynia = pd.read_csv('data\\Dane_archiwalne_PRZYBYCIA_statków_do_portu_Gdynia_2005-06.2020.csv', sep=';', names=column_names, encoding='latin2', skiprows=1)\r\n",
    "police = pd.read_csv('data\\Dane_archiwalne_PRZYBYCIA_statków_do_portu_Police_2008_-_09.2020_DpWrvve.csv', sep=';', names=column_names, encoding='latin2', skiprows=1)\r\n",
    "swinoujscie = pd.read_csv('data\\Dane_archiwalne_PRZYBYCIA_statków_do_portu_Świnoujście_2008_-_09.2020.csv', sep=';', names=column_names, encoding='latin2', skiprows=1)\r\n",
    "szczecin = pd.read_csv('data\\Dane_archiwalne_PRZYBYCIA_statków_do_portu_Szczecin_2008_-_09.2020_cmds6IL.csv', sep=';', names=column_names, encoding='latin2', skiprows=1)\r\n",
    "ustka = pd.read_csv('data\\Dane_archiwalne_PRZYBYCIA_statków_do_portu_Ustka_2005-06.2020.csv', sep=';', names=column_names, encoding='latin2', skiprows=1)\r\n",
    "kolobrzeg = pd.read_csv('data\\Dane_archiwalne_PRZYBYCIA_statków_Kołobrzeg_2005_-_09.2020.csv', sep=';', names=column_names, encoding='latin2', skiprows=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# create list of each seaport's data and its names\r\n",
    "seaports = [darlowo, gdansk, gdansk_nowy_port, gdynia, police, swinoujscie, szczecin, ustka, kolobrzeg]\r\n",
    "seaports_names = ['darlowo', 'gdansk', 'gdansk_nowy_port', 'gdynia', 'police', 'swinoujscie', 'szczecin', 'ustka', 'kolobrzeg']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## View dataframes shapes and cumulative number of rows"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# view shape\r\n",
    "for index, seaport in enumerate(seaports_names):\r\n",
    "    print(seaport, ': ', seaports[index].shape)\r\n",
    "\r\n",
    "# view cumulative number of rows\r\n",
    "sum = 0\r\n",
    "for seaport in seaports:\r\n",
    "    sum += len(seaport)\r\n",
    "print('Cumulative number of rows: ', sum)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "darlowo :  (1100, 12)\n",
      "gdansk :  (11557, 12)\n",
      "gdansk_nowy_port :  (29720, 12)\n",
      "gdynia :  (42729, 12)\n",
      "police :  (3676, 12)\n",
      "swinoujscie :  (65765, 12)\n",
      "szczecin :  (38873, 12)\n",
      "ustka :  (159, 12)\n",
      "kolobrzeg :  (2703, 12)\n",
      "Cumulative number of rows:  196282\n"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Merge data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "df = pd.DataFrame()\r\n",
    "for seaport in seaports:\r\n",
    "    df = df.append(seaport)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Remove unnecessary columns: 'Berth', 'Agent', \"Ship's name\", 'Call sign', 'Gross capacity'\r\n",
    "### I have found out that ships names and call signs are used for identification, but they are likely to change. This makes IMO number the best for identification purpose, so I have removed those 2 columns.\r\n",
    "### 'Berth', 'Agent' and 'Gross capacity' are useless for visualisation purpose."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "df = df.drop(['Berth', 'Agent', \"Ship's name\", 'Call sign', 'Gross capacity'], axis=1)\r\n",
    "df.columns"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['Destination seaport code', 'Arrival date', 'Arrival time',\n",
       "       'Departure seaport code', 'Cockade', 'IMO number', 'Length'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## View unique values in each column"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "for column in df.columns:\r\n",
    "    print(column, ': ', df[column].nunique())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Destination seaport code :  9\n",
      "Arrival date :  10447\n",
      "Arrival time :  1206\n",
      "Departure seaport code :  1626\n",
      "Cockade :  186\n",
      "IMO number :  11487\n",
      "Length :  6858\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## COLUMN: Arrival date\r\n",
    "### Change 'Arrival date' column type and filter by years (we know that data about different seaports are from different periods, but we want them to be from the same)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# convert type\r\n",
    "df['Arrival date'] = pd.to_datetime(df['Arrival date'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "start_date = '2008-01-01'\r\n",
    "end_date = '2019-12-31'\r\n",
    "\r\n",
    "# remove data from undesirable date range\r\n",
    "df = df[(df['Arrival date'] >= start_date) & (df['Arrival date'] <= end_date)]\r\n",
    "print('Arrival date range:  ', df['Arrival date'].min().date(), '  -  ', df['Arrival date'].max().date())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Arrival date range:   2008-01-01   -   2019-12-31\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## COLUMN: Arrival day of week\r\n",
    "### Adding column containing day of week of arrival"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "df['Arrival day of week'] = df['Arrival date'].dt.day_name()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## COLUMN: IMO number\r\n",
    "### There is no accessible dataset with IMO numbers of ships, so I scrape this data (together with ship's length) from https://www.vesselfinder.com/"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# check if IMO numbers follow official pattern (7-digits number)\r\n",
    "df['IMO number'] = df['IMO number'].astype(str)\r\n",
    "df['IMO number'][df['IMO number'].str.isnumeric() == False] = np.nan\r\n",
    "df['IMO number'][df['IMO number'].str.len() != 7] = np.nan\r\n",
    "\r\n",
    "# save IMO numbers with correct format as list\r\n",
    "imo_numbers_list = df['IMO number'].unique().tolist()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Use scraping script"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "from scraping_fun import scrape\r\n",
    "scrape(imo_numbers_list)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# read data from file created by scrape()\r\n",
    "scraped_length = pd.read_csv('data\\scraped_length.csv')\r\n",
    "\r\n",
    "# change type of imo number to be string (neccesary for further tasks)\r\n",
    "scraped_length['imo'] = scraped_length['imo'].astype(pd.Int32Dtype()).astype(str)\r\n",
    "\r\n",
    "# check if IMO number exists and placing np.nan for ships parameters if not\r\n",
    "df['IMO number'][df['IMO number'].isin(scraped_length['imo']) == False] = np.nan\r\n",
    "df['Cockade'][df['IMO number'].isin(scraped_length['imo']) == False] = np.nan\r\n",
    "df['Length'][df['IMO number'].isin(scraped_length['imo']) == False] = np.nan"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## COLUMN: Length"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# create list of correct IMO numbers\r\n",
    "correct_imo_numbers = df['IMO number'][df['IMO number'].isin(scraped_length[\"imo\"]) == True].tolist()\r\n",
    "\r\n",
    "# iterate through list of correct IMO numbers\r\n",
    "for imo_number in correct_imo_numbers:\r\n",
    "    # I use try and except to avoid error when trying to convert missing value to int\r\n",
    "    try:\r\n",
    "        # assign length from scraped data\r\n",
    "        df['Length'][df['IMO number'] == imo_number] = int(scraped_length['length'][scraped_length['imo'] == imo_number])\r\n",
    "    except:\r\n",
    "        None"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# convert numeric values to int to finally check their correctness\r\n",
    "df['Length'] = df['Length'].astype(str).astype(float).round(0).astype(pd.Int32Dtype())\r\n",
    "df['IMO number'] = df['IMO number'].astype(str).astype(float).round(0).astype(pd.Int32Dtype())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## COLUMN: Departure seaport code"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# place NaNs when length if incorrect\r\n",
    "df['Departure seaport code'] = df['Departure seaport code'].astype(str)\r\n",
    "df['Departure seaport code'][df['Departure seaport code'].str.len() != 5] = np.nan"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create dictionary with abbreviations and full names of countries"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# read country abbreviations dataset\r\n",
    "country_codes = pd.read_excel('data\\-nzcs-344---nz-border-agencies-advance-notice-of-arrival---tsw-csv-upload-version.xlsx', sheet_name='Country Codes', header=4, usecols='B:C')\r\n",
    "\r\n",
    "# view top 5 rows\r\n",
    "print(country_codes.head())\r\n",
    "\r\n",
    "# change type from dataframe to dictionary\r\n",
    "country_codes = country_codes.set_index('Country Code').to_dict()['Name']"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "             Name Country Code\n",
      "0     Afghanistan           AF\n",
      "1   Aland Islands           AX\n",
      "2         Albania           AL\n",
      "3         Algeria           DZ\n",
      "4  American Samoa           AS\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create list of correct seaport codes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# read seaports information dataset\r\n",
    "seaport_codes = pd.read_csv('data\\code-list_csv.csv', header=0, usecols=[1,2])\r\n",
    "\r\n",
    "# view top 5 rows\r\n",
    "print(seaport_codes.head())\r\n",
    "\r\n",
    "# combine country and location abbreviations to create seport code\r\n",
    "seaport_codes['Seaport code'] = seaport_codes['Country'] + seaport_codes['Location']\r\n",
    "\r\n",
    "# drop 'Country' and 'Location' columns\r\n",
    "seaport_codes = seaport_codes.drop(['Country', 'Location'], axis=1)\r\n",
    "\r\n",
    "# change list from column values\r\n",
    "seaport_codes = seaport_codes['Seaport code'].tolist()\r\n",
    "\r\n",
    "# view top 5 created seaport codes\r\n",
    "seaport_codes[:5]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  Country Location\n",
      "0      AD      ALV\n",
      "1      AD      CAN\n",
      "2      AD      ENC\n",
      "3      AD      ESC\n",
      "4      AD      EAC\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['ADALV', 'ADCAN', 'ADENC', 'ADESC', 'ADEAC']"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# place NaNs for incorrect seaport codes\r\n",
    "df['Departure seaport code'][df['Departure seaport code'].isin(seaport_codes) == False] = np.nan"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ADD COLUMN: Departure country"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# extract country abbreviation (2 first digits of seaport code) and replace using country_codes dictionary\r\n",
    "df['Departure country'] = df['Departure seaport code'].str[0:2].replace(country_codes)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## COLUMN: Cockade"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# view unique values of 'Cockade' column\r\n",
    "df.Cockade = df.Cockade.astype(str)\r\n",
    "print('Cackade column unique values: ', df.Cockade.nunique())\r\n",
    "np.sort(df.Cockade.unique())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cackade column unique values:  163\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['AG', 'AN', 'ANTIGUA & BARBUDA', 'Afghanistan', 'Algeria',\n",
       "       'Anguilla', 'Antigua and Barbuda', 'Argentina', 'Azerbaijan', 'BB',\n",
       "       'BE', 'BS', 'BZ', 'Bahamas', 'Bangladesh', 'Barbados', 'Belgium',\n",
       "       'Belize', 'Bermuda', 'Brazil', 'British Indian Ocean Territory',\n",
       "       'Bulgaria', 'COOK ISLANDS', 'CW', 'CY', 'Cambodia', 'Canada',\n",
       "       'Cayman Islands', 'China', 'Cocos (Keeling) Islands', 'Comoros',\n",
       "       'Cook Islands', 'Croatia', 'Curaçao', 'Cyprus', 'DE', 'DK',\n",
       "       'Denmark', 'Dominica', 'Dominican Republic', 'Egypt', 'Estonia',\n",
       "       'FI', 'FINLAND', 'FO', 'Faroe Islands', 'Finland', 'France',\n",
       "       'French Polynesia', 'GB', 'GERMANY', 'GI', 'Georgia', 'Germany',\n",
       "       'Ghana', 'Gibraltar', 'Greece', 'Greenland', 'HK', 'Honduras',\n",
       "       'Hong Kong', 'Hong Kong ', 'Hungary', 'IE', 'IM', 'Iceland',\n",
       "       'India', 'Indonesia', 'Ireland', 'Isle of Man', 'Israel', 'Italy',\n",
       "       'Jamaica', 'Japan', 'KN', 'KY', 'Kiribati',\n",
       "       \"Korea Democratic People's Republic of\", 'Korea Republic of',\n",
       "       'Kuwait', 'LATVIA', 'LR', 'LT', 'LU', 'LV', 'Latvia', 'Lebanon',\n",
       "       'Liberia', 'Libya', 'Libyan Arab Jamahiriya', 'Lithuania',\n",
       "       'Luxembourg', 'MH', 'MT', 'Macau', 'Malaysia', 'Mali', 'Malta',\n",
       "       'Marshall Islands', 'Mauritius', 'Mexico', 'Moldova Republic of',\n",
       "       'Montenegro', 'Myanmar', 'NETHERLANDS', 'NL', 'NO', 'Netherlands',\n",
       "       'Netherlands Antilles', 'Norfolk Island', 'Norway', 'PA', 'PANAMA',\n",
       "       'PL', 'PT', 'Palau', 'Panama', 'Peru', 'Philippines', 'Poland',\n",
       "       'Portugal', 'Puerto Rico', 'Qatar', 'RU', 'RUSSIA', 'Romania',\n",
       "       'Russian Federation', 'SE', 'SG', 'SWEDEN', 'Saint Helena',\n",
       "       'Saint Kitts and Nevis', 'Saint Lucia',\n",
       "       'Saint Vincent and the Grenadines', 'Saudi Arabia', 'Senegal',\n",
       "       'Serbia and Montenegro', 'Seychelles', 'Sierra Leone', 'Singapore',\n",
       "       'Slovakia', 'Spain', 'Sri Lanka', 'Sweden', 'Switzerland',\n",
       "       'Syrian Arab Republic', 'TR', 'Taiwan Province of China',\n",
       "       'Tanzania United Republic of', 'Thailand', 'Togo', 'Turkey',\n",
       "       'Tuvalu', 'Ukraine', 'United Arab Emirates', 'United Kingdom',\n",
       "       'United States', 'Uruguay', 'VC', 'Vanuatu', 'Viet Nam',\n",
       "       'Wallis and Futuna', 'nan'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "%%capture\r\n",
    "# correct and unify country names using country converter library\r\n",
    "import country_converter as coco\r\n",
    "df.Cockade = coco.convert(names=df.Cockade, to='name_short', not_found=None)\r\n",
    "\r\n",
    "# replace 'nan' string with np.nan\r\n",
    "df['Cockade'][df.Cockade == 'nan'] = np.nan"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# view results\r\n",
    "print('Cackade column unique values: ', df.Cockade.nunique())\r\n",
    "np.sort(df.Cockade.astype(str).unique())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cackade column unique values:  117\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['AN', 'Afghanistan', 'Algeria', 'Anguilla', 'Antigua and Barbuda',\n",
       "       'Argentina', 'Azerbaijan', 'Bahamas', 'Bangladesh', 'Barbados',\n",
       "       'Belgium', 'Belize', 'Bermuda', 'Brazil',\n",
       "       'British Indian Ocean Territory', 'Bulgaria', 'Cambodia', 'Canada',\n",
       "       'Cayman Islands', 'China', 'Cocos (Keeling) Islands', 'Comoros',\n",
       "       'Cook Islands', 'Croatia', 'Curacao', 'Cyprus', 'Denmark',\n",
       "       'Dominica', 'Dominican Republic', 'Egypt', 'Estonia',\n",
       "       'Faeroe Islands', 'Finland', 'France', 'French Polynesia',\n",
       "       'Georgia', 'Germany', 'Ghana', 'Gibraltar', 'Greece', 'Greenland',\n",
       "       'Honduras', 'Hong Kong', 'Hungary', 'Iceland', 'India',\n",
       "       'Indonesia', 'Ireland', 'Isle of Man', 'Israel', 'Italy',\n",
       "       'Jamaica', 'Japan', 'Kiribati', 'Kuwait', 'Latvia', 'Lebanon',\n",
       "       'Liberia', 'Libya', 'Lithuania', 'Luxembourg', 'Macau', 'Malaysia',\n",
       "       'Mali', 'Malta', 'Marshall Islands', 'Mauritius', 'Mexico',\n",
       "       'Moldova', 'Montenegro', 'Myanmar', 'Netherlands',\n",
       "       'Netherlands Antilles', 'Norfolk Island', 'North Korea', 'Norway',\n",
       "       'Palau', 'Panama', 'Peru', 'Philippines', 'Poland', 'Portugal',\n",
       "       'Puerto Rico', 'Qatar', 'Romania', 'Russia', 'Saudi Arabia',\n",
       "       'Senegal', 'Serbia and Montenegro', 'Seychelles', 'Sierra Leone',\n",
       "       'Singapore', 'Slovakia', 'South Korea', 'Spain', 'Sri Lanka',\n",
       "       'St. Helena', 'St. Kitts and Nevis', 'St. Lucia',\n",
       "       'St. Vincent and the Grenadines', 'Sweden', 'Switzerland', 'Syria',\n",
       "       'Taiwan', 'Tanzania', 'Thailand', 'Togo', 'Turkey', 'Tuvalu',\n",
       "       'Ukraine', 'United Arab Emirates', 'United Kingdom',\n",
       "       'United States', 'Uruguay', 'Vanuatu', 'Vietnam',\n",
       "       'Wallis and Futuna Islands', 'nan'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Delete empty rows"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "df = df.dropna(axis=0, how='all')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Take last look at summary statistics"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "df.info()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 182828 entries, 108 to 2630\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count   Dtype         \n",
      "---  ------                    --------------   -----         \n",
      " 0   Destination seaport code  182828 non-null  object        \n",
      " 1   Arrival date              182828 non-null  datetime64[ns]\n",
      " 2   Arrival time              182828 non-null  object        \n",
      " 3   Departure seaport code    170930 non-null  object        \n",
      " 4   Cockade                   172031 non-null  object        \n",
      " 5   IMO number                172031 non-null  Int32         \n",
      " 6   Length                    172031 non-null  Int32         \n",
      " 7   Arrival day of week       182828 non-null  object        \n",
      " 8   Departure country         182828 non-null  object        \n",
      "dtypes: Int32(2), datetime64[ns](1), object(6)\n",
      "memory usage: 12.9+ MB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "df.describe().transpose()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "               count          mean            std        min        25%  \\\n",
       "IMO number  172031.0  8.694822e+06  765601.705071  1002495.0  8124486.0   \n",
       "Length      172031.0  1.243571e+02      53.181478       10.0       87.0   \n",
       "\n",
       "                  50%        75%        max  \n",
       "IMO number  9019078.0  9255268.0  9869588.0  \n",
       "Length          125.0      164.0      400.0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>IMO number</th>\n",
       "      <td>172031.0</td>\n",
       "      <td>8.694822e+06</td>\n",
       "      <td>765601.705071</td>\n",
       "      <td>1002495.0</td>\n",
       "      <td>8124486.0</td>\n",
       "      <td>9019078.0</td>\n",
       "      <td>9255268.0</td>\n",
       "      <td>9869588.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Length</th>\n",
       "      <td>172031.0</td>\n",
       "      <td>1.243571e+02</td>\n",
       "      <td>53.181478</td>\n",
       "      <td>10.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    Destination seaport code Arrival date Arrival time Departure seaport code  \\\n",
       "108                    PLDAR   2008-01-20     09:30:00                  GBGSY   \n",
       "109                    PLDAR   2008-11-19     09:40:00                  DERSK   \n",
       "110                    PLDAR   2009-01-22     09:00:00                  DKSKA   \n",
       "111                    PLDAR   2009-01-25     08:00:00                  DKSVE   \n",
       "112                    PLDAR   2009-02-11     18:30:00                  SEVAG   \n",
       "\n",
       "                            Cockade  IMO number  Length Arrival day of week  \\\n",
       "108                          Russia     8700060      82              Sunday   \n",
       "109             Antigua and Barbuda     6617855      68           Wednesday   \n",
       "110                          Panama     7013721      41            Thursday   \n",
       "111  St. Vincent and the Grenadines     7821049      63              Sunday   \n",
       "112                         Germany     8975902      31           Wednesday   \n",
       "\n",
       "    Departure country  \n",
       "108    United Kingdom  \n",
       "109           Germany  \n",
       "110           Denmark  \n",
       "111           Denmark  \n",
       "112            Sweden  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Destination seaport code</th>\n",
       "      <th>Arrival date</th>\n",
       "      <th>Arrival time</th>\n",
       "      <th>Departure seaport code</th>\n",
       "      <th>Cockade</th>\n",
       "      <th>IMO number</th>\n",
       "      <th>Length</th>\n",
       "      <th>Arrival day of week</th>\n",
       "      <th>Departure country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>PLDAR</td>\n",
       "      <td>2008-01-20</td>\n",
       "      <td>09:30:00</td>\n",
       "      <td>GBGSY</td>\n",
       "      <td>Russia</td>\n",
       "      <td>8700060</td>\n",
       "      <td>82</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>PLDAR</td>\n",
       "      <td>2008-11-19</td>\n",
       "      <td>09:40:00</td>\n",
       "      <td>DERSK</td>\n",
       "      <td>Antigua and Barbuda</td>\n",
       "      <td>6617855</td>\n",
       "      <td>68</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>PLDAR</td>\n",
       "      <td>2009-01-22</td>\n",
       "      <td>09:00:00</td>\n",
       "      <td>DKSKA</td>\n",
       "      <td>Panama</td>\n",
       "      <td>7013721</td>\n",
       "      <td>41</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>Denmark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>PLDAR</td>\n",
       "      <td>2009-01-25</td>\n",
       "      <td>08:00:00</td>\n",
       "      <td>DKSVE</td>\n",
       "      <td>St. Vincent and the Grenadines</td>\n",
       "      <td>7821049</td>\n",
       "      <td>63</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>Denmark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>PLDAR</td>\n",
       "      <td>2009-02-11</td>\n",
       "      <td>18:30:00</td>\n",
       "      <td>SEVAG</td>\n",
       "      <td>Germany</td>\n",
       "      <td>8975902</td>\n",
       "      <td>31</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Sweden</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save data to data.csv"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "df.to_csv('data\\seaports_cleaned.csv', sep=',', index=False)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "4b6bb01a86991dd9836ebdd8d6a2d434e1184197b5d53f71907b736bd5c1de2b"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}